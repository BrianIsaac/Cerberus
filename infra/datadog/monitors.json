{
  "description": "Governance monitors for AI agent fleet bounded autonomy controls",
  "monitors": [
    {
      "name": "AI Agent Fleet - Governance Escalation Rate",
      "type": "metric alert",
      "query": "sum(last_15m):sum:ai_agent.governance.escalation{team:ai-agents}.as_count() > 10",
      "message": "## Summary\nHigh governance escalation rate across AI agent fleet.\n\n## Impact\n- Multiple agents requiring human intervention\n- Potential security or policy concerns\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet Governance Escalation Rate\n- Window: Last 15 minutes\n- Threshold: escalations > 10\n- Escalation count: {{value}}\n\n## Escalation Breakdown\nCheck by reason tag:\n- security_violation\n- step_budget_exceeded\n- model_budget_exceeded\n- tool_budget_exceeded\n- low_confidence\n- pii_detected\n\n## Next Actions\n- [ ] Review escalation traces by service\n- [ ] Check for common patterns\n- [ ] Verify governance thresholds\n\n@ops-oncall @security-team",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 10,
          "warning": 5
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 2
    },
    {
      "name": "AI Agent Fleet - Security Violation Spike",
      "type": "metric alert",
      "query": "sum(last_5m):sum:ai_agent.governance.escalation{team:ai-agents,reason:security_violation}.as_count() > 3",
      "message": "## Summary\nSecurity validation failures detected across AI agent fleet.\n\n## Impact\n- Potential prompt injection or attack attempts\n- Security policy enforcement active\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet Security Violation Spike\n- Window: Last 5 minutes\n- Threshold: violations > 3\n- Violation count: {{value}}\n\n## Next Actions\n- [ ] Review blocked requests immediately\n- [ ] Check for attack patterns\n- [ ] Verify security validator rules\n\n@ops-oncall @security-team",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "monitor_type:security",
        "severity:critical"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 30,
        "thresholds": {
          "critical": 3,
          "warning": 1
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 1
    },
    {
      "name": "AI Agent Fleet - PII Detection",
      "type": "metric alert",
      "query": "sum(last_15m):sum:ai_agent.governance.escalation{team:ai-agents,reason:pii_detected}.as_count() > 0",
      "message": "## Summary\nPII detected in user input to AI agents.\n\n## Impact\n- Personal data being submitted to agents\n- Privacy compliance concerns\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet PII Detection\n- Window: Last 15 minutes\n- Threshold: detections > 0\n- Detection count: {{value}}\n\n## Next Actions\n- [ ] Review traces with PII detection\n- [ ] Verify PII was properly handled\n- [ ] Consider user education on data submission\n\n@ops-oncall @privacy-team",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "monitor_type:privacy",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 0
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 2
    },
    {
      "name": "AI Agent Fleet - Budget Utilisation High",
      "type": "metric alert",
      "query": "avg(last_15m):avg:ai_agent.governance.budget_utilisation{team:ai-agents} > 0.8",
      "message": "## Summary\nHigh budget utilisation across AI agent fleet - agents frequently approaching limits.\n\n## Impact\n- Requests may be escalated before completion\n- Potential cost overruns\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet Budget Utilisation High\n- Window: Last 15 minutes\n- Threshold: utilisation > 80%\n- Current utilisation: {{value}}\n\n## Budget Types\nCheck budget_type tag:\n- step: Agent execution steps\n- model: LLM API calls\n- tool: External tool calls\n\n## Next Actions\n- [ ] Review high-utilisation traces\n- [ ] Consider budget limit adjustments\n- [ ] Optimise agent efficiency\n\n@ops-oncall",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "monitor_type:cost",
        "severity:warning"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 120,
        "thresholds": {
          "critical": 0.8,
          "warning": 0.6
        },
        "include_tags": true
      },
      "priority": 3
    },
    {
      "name": "AI Agent Fleet - Approval Queue Backlog",
      "type": "metric alert",
      "query": "sum(last_5m):sum:ai_agent.governance.approval_pending{team:ai-agents}.as_count() > 20",
      "message": "## Summary\nHigh number of pending approvals across AI agent fleet.\n\n## Impact\n- Delayed execution of agent actions\n- Users waiting for human approval\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet Approval Queue Backlog\n- Window: Last 5 minutes\n- Threshold: pending > 20\n- Pending count: {{value}}\n\n## Next Actions\n- [ ] Review pending approval queue\n- [ ] Increase approval team capacity\n- [ ] Consider auto-approval thresholds\n\n@ops-oncall @approval-team",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "severity:warning"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 20,
          "warning": 10
        },
        "include_tags": true
      },
      "priority": 3
    },
    {
      "name": "AI Agent Fleet - Low Quality Score",
      "type": "metric alert",
      "query": "avg(last_15m):avg:ai_agent.quality_score{team:ai-agents,score_type:code_quality} < 0.7",
      "message": "## Summary\nLow quality scores detected from LLM-as-judge evaluation.\n\n## Impact\n- Generated content may require review\n- Potential accuracy or safety concerns\n- Team: {{team.name}}\n\n## What Triggered\n- Monitor: Fleet Low Quality Score\n- Window: Last 15 minutes\n- Threshold: quality score < 0.7\n- Current score: {{value}}\n\n## Score Types\nCheck score_type tag:\n- code_quality: Overall code quality\n- correctness_score: Functional correctness\n- safety_score: Safety compliance\n\n## Next Actions\n- [ ] Review low-quality traces\n- [ ] Check LLM model performance\n- [ ] Verify prompt templates\n\n@ops-oncall @ml-team",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "monitor_type:quality",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 120,
        "thresholds": {
          "critical": 0.7,
          "warning": 0.75
        },
        "include_tags": true
      },
      "priority": 2
    }
  ]
}
