{
  "monitors": [
    {
      "name": "AI Agents - High P95 Latency",
      "type": "metric alert",
      "query": "avg(last_5m):p95:trace.http.request.duration{team:ai-agents} by {service} > 10",
      "message": "## Summary\nThe P95 request latency for AI agent has exceeded 10 seconds.\n\n## Impact\n- Users experiencing slow response times\n- Service: {{service.name}}\n- Environment: {{env.name}}\n\n## What Triggered\n- Monitor: High P95 Latency\n- Window: Last 5 minutes\n- Threshold: P95 latency > 10 seconds\n- Current value: {{value}} seconds\n\n## Evidence\n- [View traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}})\n- [Latency dashboard](https://app.ap1.datadoghq.com/dashboard)\n\n## Likely Causes\n1. LLM API latency spike\n2. Tool execution timeouts\n3. MCP server slow responses\n4. Database or cache issues\n\n## Next Actions\n- [ ] Check LLM API status\n- [ ] Review tool latency breakdown\n- [ ] Investigate slow traces\n- [ ] Review resource utilisation\n\n@ops-oncall @incident-ai-agents-latency",
      "tags": [
        "team:ai-agents",
        "monitor_type:latency",
        "severity:warning"
      ],
      "options": {
        "notify_no_data": false,
        "no_data_timeframe": 10,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 10,
          "warning": 8
        },
        "notify_audit": true,
        "require_full_window": false,
        "include_tags": true
      },
      "priority": 3
    },
    {
      "name": "AI Agents - Step Budget Exceeded",
      "type": "metric alert",
      "query": "sum(last_5m):sum:ai_agent.step_budget_exceeded{team:ai-agents} by {service}.as_count() > 0",
      "message": "## Summary\nAgent runaway detected - step budget exceeded on one or more requests.\n\n## Impact\n- Requests consuming excessive compute resources\n- Potential cost overruns\n- Service: {{service.name}}\n\n## What Triggered\n- Monitor: Step Budget Exceeded\n- Window: Last 5 minutes\n- Threshold: count > 0\n- Exceeded count: {{value}}\n\n## Evidence\n- [View affected traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20%40agent.steps%3A%3E%3D8)\n- [Agent metrics dashboard](https://app.ap1.datadoghq.com/dashboard)\n\n## Likely Causes\n1. Complex user queries requiring many iterations\n2. Tool errors causing retry loops\n3. LLM producing invalid outputs repeatedly\n4. Prompt engineering issues\n\n## Next Actions\n- [ ] Review traces hitting step cap\n- [ ] Analyse LLM response quality\n- [ ] Check tool error rates\n- [ ] Review prompt templates\n- [ ] Consider adjusting step budget\n\n@ops-oncall @incident-ai-agents-budget",
      "tags": [
        "team:ai-agents",
        "monitor_type:governance",
        "severity:warning"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 0
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 3
    },
    {
      "name": "AI Agents - Tool Error Rate Spike",
      "type": "metric alert",
      "query": "avg(last_5m):sum:ai_agent.tool.errors{team:ai-agents} by {service}.as_rate() > 0.1",
      "message": "## Summary\nTool reliability failure detected - error rate spike across tools.\n\n## Impact\n- Degraded agent functionality\n- Failed tool queries\n- Incomplete results\n- Service: {{service.name}}\n- Tool: {{tool_name.name}}\n\n## What Triggered\n- Monitor: Tool Error Rate Spike\n- Window: Last 5 minutes\n- Threshold: error rate > 0.1 (10%)\n- Current rate: {{value}}\n\n## Evidence\n- [View tool errors](https://app.ap1.datadoghq.com/logs?query=service%3A{{service.name}}%20event_type%3Atool_error)\n- [Tool performance dashboard](https://app.ap1.datadoghq.com/dashboard)\n- [Recent error traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20error%3Atrue)\n\n## Likely Causes\n1. External API rate limiting\n2. MCP server connection issues\n3. Invalid API credentials\n4. Malformed tool parameters\n5. Network connectivity problems\n\n## Recommended Mitigations\n- Verify API credentials are valid\n- Check MCP server health endpoint\n- Review API rate limits\n- Implement exponential backoff\n- Check Cloud Run network configuration\n\n## Next Actions\n- [ ] Check MCP server logs\n- [ ] Verify API credentials\n- [ ] Review error distribution by tool\n- [ ] Test tool execution manually\n- [ ] Check network connectivity\n\n@ops-oncall @incident-ai-agents-tool",
      "tags": [
        "team:ai-agents",
        "monitor_type:tool_reliability",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 0.1,
          "warning": 0.05
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 2
    },
    {
      "name": "AI Agents - Quality Degradation",
      "type": "metric alert",
      "query": "avg(last_15m):avg:llmobs.evaluation.ragas_faithfulness{team:ai-agents} by {service} < 0.7",
      "message": "## Summary\nLLM quality degradation detected - faithfulness score below acceptable threshold.\n\n## Impact\n- Reduced accuracy of results\n- Potential hallucinations in responses\n- User trust degradation\n- Service: {{service.name}}\n\n## What Triggered\n- Monitor: Quality Degradation\n- Window: Last 15 minutes\n- Threshold: RAGAS faithfulness < 0.7\n- Current score: {{value}}\n\n## Evidence\n- [Lowest quality traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20%40llmobs.evaluation.ragas_faithfulness%3A%3C0.7)\n- [Quality evaluation dashboard](https://app.ap1.datadoghq.com/dashboard)\n- [Hallucination rate graph](https://app.ap1.datadoghq.com/dashboard)\n\n## Quality Context\n- Faithfulness score: {{value}}\n- Baseline (1h ago): [link to metric]\n- Hallucination rate: [link to metric]\n- Topic relevancy: [link to metric]\n\n## Likely Causes\n1. LLM model behaviour drift\n2. Prompt template regression\n3. Context quality degradation\n4. Tool failures affecting input quality\n5. Model version change\n\n## Next Actions\n- [ ] Review top 5 lowest quality traces\n- [ ] Compare prompts to baseline\n- [ ] Check LLM model version\n- [ ] Analyse context retrieval quality\n- [ ] Review recent prompt changes\n- [ ] Consider rollback if recent deploy\n\n@ops-oncall @ml-team @incident-ai-agents-quality",
      "tags": [
        "team:ai-agents",
        "monitor_type:quality",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 120,
        "thresholds": {
          "critical": 0.7,
          "warning": 0.75
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 2
    },
    {
      "name": "AI Agents - Hallucination Rate High",
      "type": "metric alert",
      "query": "avg(last_15m):sum:llmobs.evaluation.hallucination.fail{team:ai-agents} by {service}.as_count() / sum:llmobs.evaluation.hallucination.total{team:ai-agents} by {service}.as_count() * 100 > 10",
      "message": "## Summary\nHallucination rate exceeds 10% - LLM producing ungrounded responses.\n\n## Impact\n- Users receiving inaccurate information\n- Potential incorrect decisions based on output\n- Service credibility at risk\n- Service: {{service.name}}\n\n## What Triggered\n- Monitor: Hallucination Rate High\n- Window: Last 15 minutes\n- Threshold: hallucination rate > 10%\n- Current rate: {{value}}%\n\n## Evidence\n- [Hallucinated responses](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20%40llmobs.evaluation.hallucination%3Afail)\n- [Quality dashboard](https://app.ap1.datadoghq.com/dashboard)\n\n## Next Actions\n- [ ] Review hallucinated traces\n- [ ] Check context retrieval quality\n- [ ] Verify prompt grounding instructions\n- [ ] Consider increasing temperature penalties\n\n@ops-oncall @ml-team @incident-ai-agents-quality",
      "tags": [
        "team:ai-agents",
        "monitor_type:quality",
        "severity:critical"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 120,
        "thresholds": {
          "critical": 10,
          "warning": 5
        },
        "include_tags": true
      },
      "priority": 1
    },
    {
      "name": "AI Agents - PII Detection Alert",
      "type": "log alert",
      "query": "logs(\"team:ai-agents @sensitive_data_scanner.pii_detected:*\").index(\"*\").rollup(\"count\").last(\"5m\") > 0",
      "message": "## SECURITY ALERT\nPII detected in LLM interactions - immediate attention required.\n\n## Impact\n- **CRITICAL SECURITY ISSUE**\n- Potential data privacy violation\n- Compliance risk\n- Service: {{service.name}}\n- PII Type: {{pii_type.name}}\n\n## What Triggered\n- Monitor: PII Detection\n- Window: Last 5 minutes\n- Threshold: PII detected count > 0\n- Detection count: {{value}}\n\n## Evidence\n- [PII detection logs](https://app.ap1.datadoghq.com/logs?query=team%3Aai-agents%20%40sensitive_data_scanner.pii_detected%3A*)\n- Trace ID: [in logs]\n- PII type: [from sensitive data scanner]\n- Redacted sample: [from logs]\n\n## Immediate Actions Required\n- [ ] Review affected traces immediately\n- [ ] Verify data scanner configuration\n- [ ] Check if PII was logged/stored\n- [ ] Assess compliance impact\n- [ ] Document incident\n- [ ] Notify security team\n\n@security-team @ops-oncall @incident-ai-agents-security",
      "tags": [
        "team:ai-agents",
        "monitor_type:security",
        "severity:critical",
        "compliance:pii"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 0,
        "thresholds": {
          "critical": 0
        },
        "notify_audit": true,
        "include_tags": true,
        "enable_logs_sample": true
      },
      "priority": 1
    },
    {
      "name": "AI Agents - MCP Server Connection Issues",
      "type": "metric alert",
      "query": "sum(last_5m):sum:trace.llmobs.span.error{mcp.session.initialize,team:ai-agents} by {service}.as_count() > 5",
      "message": "## Summary\nMCP Server connection issues detected - tool infrastructure degraded.\n\n## Impact\n- Tool query functionality unavailable\n- Agent cannot access external data sources\n- Service functionality severely limited\n- Service: {{service.name}}\n- MCP Server: {{mcp.server.name}}\n\n## What Triggered\n- Monitor: MCP Server Health\n- Window: Last 5 minutes\n- Threshold: connection errors > 5\n- Error count: {{value}}\n\n## Evidence\n- [MCP connection traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20span_name%3Amcp.session.initialize%20error%3Atrue)\n- [MCP server logs](https://app.ap1.datadoghq.com/logs?query=service%3A*mcp*)\n- Error distribution by type: [link]\n\n## MCP Server Context\n- Server name: {{mcp.server.name}}\n- Transport: {{mcp.transport}}\n- Error types: {{error.type}}\n- Recent errors: [trace links]\n\n## Likely Causes\n1. MCP server instance down\n2. Network connectivity issues\n3. Authentication failure (service account)\n4. MCP server deployment failed\n5. Resource exhaustion on server\n\n## Recommended Mitigations\n1. Check MCP server status\n2. Verify service-to-service IAM permissions\n3. Restart MCP server instance\n4. Check API key secrets\n5. Review logs for MCP server\n6. Verify network configuration\n\n## Next Actions\n- [ ] Check MCP server status\n- [ ] Review MCP server logs\n- [ ] Verify IAM bindings\n- [ ] Test MCP health endpoint\n- [ ] Check recent deployments\n- [ ] Restart if necessary\n\n@ops-oncall @sre-team @incident-ai-agents-mcp",
      "tags": [
        "team:ai-agents",
        "monitor_type:mcp_health",
        "severity:critical",
        "component:mcp-server"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 5,
          "warning": 3
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 1
    },
    {
      "name": "AI Agents - Token Budget Spike",
      "type": "metric alert",
      "query": "avg(last_15m):avg:llmobs.tokens.total{team:ai-agents} by {service} > 50000",
      "message": "## Summary\nToken usage spike detected - potential cost overrun.\n\n## Impact\n- Higher than expected API costs\n- Service: {{service.name}}\n\n## What Triggered\n- Monitor: Token Budget Spike\n- Window: Last 15 minutes\n- Threshold: average tokens > 50,000 per request\n- Current average: {{value}} tokens\n\n## Evidence\n- [High token traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20%40llmobs.tokens.total%3A%3E50000)\n- [Cost dashboard](https://app.ap1.datadoghq.com/dashboard)\n\n## Likely Causes\n1. Large context windows\n2. Excessive tool outputs\n3. Verbose prompts\n4. Repeated retry loops\n\n## Next Actions\n- [ ] Review high-token traces\n- [ ] Check prompt template lengths\n- [ ] Analyse tool output sizes\n- [ ] Consider context truncation\n- [ ] Review token budget policies\n\n@ops-oncall @incident-ai-agents-cost",
      "tags": [
        "team:ai-agents",
        "monitor_type:cost",
        "severity:warning"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 120,
        "thresholds": {
          "critical": 50000,
          "warning": 30000
        },
        "include_tags": true
      },
      "priority": 3
    },
    {
      "name": "AI Agents - LLM Error Rate Spike",
      "type": "metric alert",
      "query": "avg(last_5m):sum:ai_agent.request.error{team:ai-agents} by {service}.as_count() / sum:ai_agent.request.count{team:ai-agents} by {service}.as_count() * 100 > 5",
      "message": "## Summary\nLLM request error rate exceeds 5% - service reliability degraded.\n\n## Impact\n- Users receiving errors instead of responses\n- Service reliability degradation\n- Service: {{service.name}}\n\n## What Triggered\n- Monitor: LLM Error Rate Spike\n- Window: Last 5 minutes\n- Threshold: error rate > 5%\n- Current rate: {{value}}%\n\n## Evidence\n- [Error traces](https://app.ap1.datadoghq.com/apm/traces?query=service%3A{{service.name}}%20error%3Atrue)\n- [Request dashboard](https://app.ap1.datadoghq.com/dashboard)\n\n## Likely Causes\n1. LLM API errors\n2. Input validation failures\n3. Tool execution failures\n4. Rate limiting\n5. Network issues\n\n## Next Actions\n- [ ] Review error traces\n- [ ] Check LLM API status\n- [ ] Verify input validation\n- [ ] Check rate limits\n- [ ] Review recent deployments\n\n@ops-oncall @incident-ai-agents-errors",
      "tags": [
        "team:ai-agents",
        "monitor_type:reliability",
        "severity:high"
      ],
      "options": {
        "notify_no_data": false,
        "evaluation_delay": 60,
        "thresholds": {
          "critical": 5,
          "warning": 2
        },
        "notify_audit": true,
        "include_tags": true
      },
      "priority": 2
    }
  ]
}
